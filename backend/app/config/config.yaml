loop:
  port: 31300  

llm:
  provider: "ollama"
  default_model: "gpt-oss"

  providers:
    openai:
      use_loop: false  
      api_url: "https://api.openai.com/v1/chat/completions"  
      models:
        gpt-4o:
          rpm: 2.0
          tpm: 10000000.0
        gpt-4o-mini:
          rpm: 15000.0
          tpm: 10000000.0
        gpt-4-turbo:
          rpm: 5000.0
          tpm: 10000000.0
        gpt-4:
          rpm: 500.0
          tpm: 30000.0
        gpt-4.1-mini:
          rpm: 10000.0
          tpm: 1000000.0

    ollama:
      use_loop: true  
      ollama_host: "localhost"  
      ollama_port: 11434  
      api_url: null  
      models:
        llama3.2:
          rpm: 100.0
          tpm: 100000.0
        gpt-oss:
          rpm: 100.0
          tpm: 100000.0

embedding:
  provider: "ollama" # ollama or sentence_transformer
  default_model: "embeddinggemma" # all-MiniLM-L6-v2 or embeddinggemma
