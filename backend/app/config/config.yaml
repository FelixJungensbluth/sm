llm:
  provider: "ollama"
  default_model: "gpt-oss"
  
  providers:
    openai:
      api_url: "https://api.openai.com/v1/chat/completions"
      models:
        gpt-4o:
          rpm: 5000.0
          tpm: 10000000.0
        gpt-4o-mini:
          rpm: 15000.0
          tpm: 10000000.0
        gpt-4-turbo:
          rpm: 5000.0
          tpm: 10000000.0
        gpt-4:
          rpm: 500.0
          tpm: 30000.0
        gpt-3.5-turbo:
          rpm: 10000.0
          tpm: 1000000.0
    
    ollama:
      api_url: "http://localhost:11434/api/chat"
      models:
        llama3.2:
          rpm: 100.0
          tpm: 100000.0
        gpt-oss:
          rpm: 100.0
          tpm: 100000.0

embedding:
  provider: "ollama" # ollama or sentence_transformer
  default_model: "embeddinggemma" # all-MiniLM-L6-v2 or embeddinggemma